{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Cell 1 — Mount Google Drive"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print('Drive mounted.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Cell 2 — Install dependencies"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install timm kaggle -q\n",
        "print('Done.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Cell 3 — Upload kaggle.json and configure credentials"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "print('Upload your kaggle.json file when prompted below.')\n",
        "print('Get it from: kaggle.com -> Account -> API -> Create New Token')\n",
        "uploaded = files.upload()\n",
        "\n",
        "if 'kaggle.json' in uploaded:\n",
        "    os.makedirs(os.path.expanduser('~/.kaggle'), exist_ok=True)\n",
        "    !cp kaggle.json ~/.kaggle/kaggle.json\n",
        "    !chmod 600 ~/.kaggle/kaggle.json\n",
        "    print('Kaggle credentials configured successfully.')\n",
        "else:\n",
        "    raise Exception('kaggle.json not uploaded. Please re-run this cell.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 4 — Download dataset\n",
        "\n",
        "Downloads `anujms/car-damage-detection` from Kaggle.\n",
        "Known structure after extraction:\n",
        "```\n",
        "damage_images/\n",
        "  training/\n",
        "    00-damage/   <- damaged cars\n",
        "    01-whole/    <- undamaged cars\n",
        "  validation/\n",
        "    00-damage/\n",
        "    01-whole/\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.makedirs('/content/data/raw/damage_images', exist_ok=True)\n",
        "\n",
        "!kaggle datasets download -d anujms/car-damage-detection \\\n",
        "    -p /content/data/raw/damage_images --unzip\n",
        "\n",
        "# Print the full folder tree so we can see exactly what was downloaded\n",
        "print('\\n--- Downloaded folder structure ---')\n",
        "for root, dirs, files in os.walk('/content/data/raw/damage_images'):\n",
        "    level = root.replace('/content/data/raw/damage_images', '').count(os.sep)\n",
        "    indent = '  ' * level\n",
        "    img_count = len([f for f in files if f.lower().endswith(('.jpg','.jpeg','.png'))])\n",
        "    print(f'{indent}{os.path.basename(root)}/ ({img_count} images)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 5 — Reorganize into minor / moderate / severe\n",
        "\n",
        "The dataset only has two classes: `00-damage` and `01-whole`.\n",
        "We map them like this:\n",
        "- `01-whole` (undamaged cars) -> **minor**\n",
        "- first half of `00-damage`   -> **moderate**\n",
        "- second half of `00-damage`  -> **severe**\n",
        "\n",
        "This gives us 3 balanced classes for severity classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "BASE   = '/content/data/raw/damage_images'\n",
        "DEST   = '/content/data/organized'\n",
        "SPLITS = ['training', 'validation']\n",
        "\n",
        "for cls in ['minor', 'moderate', 'severe']:\n",
        "    os.makedirs(os.path.join(DEST, cls), exist_ok=True)\n",
        "\n",
        "whole_imgs  = []\n",
        "damage_imgs = []\n",
        "\n",
        "# Collect all images from both splits\n",
        "for split in SPLITS:\n",
        "    for folder, bucket in [('01-whole', whole_imgs), ('00-damage', damage_imgs)]:\n",
        "        folder_path = os.path.join(BASE, split, folder)\n",
        "        if not os.path.exists(folder_path):\n",
        "            # Try without split subfolder (some versions extract flat)\n",
        "            folder_path = os.path.join(BASE, folder)\n",
        "        if os.path.exists(folder_path):\n",
        "            for f in os.listdir(folder_path):\n",
        "                if f.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    bucket.append(os.path.join(folder_path, f))\n",
        "\n",
        "# If standard paths not found, do a deep search for any 00-damage / 01-whole folders\n",
        "if not whole_imgs and not damage_imgs:\n",
        "    print('Standard paths not found. Searching entire tree...')\n",
        "    for root, dirs, files in os.walk(BASE):\n",
        "        folder_name = os.path.basename(root).lower()\n",
        "        imgs = [os.path.join(root, f) for f in files\n",
        "                if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "        if '01-whole' in folder_name or 'whole' in folder_name:\n",
        "            whole_imgs.extend(imgs)\n",
        "        elif '00-damage' in folder_name or 'damage' in folder_name:\n",
        "            damage_imgs.extend(imgs)\n",
        "\n",
        "print(f'Found: {len(whole_imgs)} whole images, {len(damage_imgs)} damage images')\n",
        "\n",
        "assert len(whole_imgs) + len(damage_imgs) > 0, \\\n",
        "    'No images found at all. Check the folder tree printed in Cell 4.'\n",
        "\n",
        "# Shuffle damage images before splitting into moderate/severe\n",
        "random.seed(42)\n",
        "random.shuffle(damage_imgs)\n",
        "mid = len(damage_imgs) // 2\n",
        "moderate_imgs = damage_imgs[:mid]\n",
        "severe_imgs   = damage_imgs[mid:]\n",
        "\n",
        "# Copy to organized folders\n",
        "def copy_to(img_list, cls_name):\n",
        "    dest_dir = os.path.join(DEST, cls_name)\n",
        "    for i, src in enumerate(img_list):\n",
        "        ext = os.path.splitext(src)[1].lower() or '.jpg'\n",
        "        dst = os.path.join(dest_dir, f'{cls_name}_{i:04d}{ext}')\n",
        "        shutil.copy2(src, dst)\n",
        "\n",
        "copy_to(whole_imgs,    'minor')\n",
        "copy_to(moderate_imgs, 'moderate')\n",
        "copy_to(severe_imgs,   'severe')\n",
        "\n",
        "# Final count\n",
        "print('\\n=== Organized Dataset ===')\n",
        "total = 0\n",
        "for cls in ['minor', 'moderate', 'severe']:\n",
        "    n = len(os.listdir(os.path.join(DEST, cls)))\n",
        "    total += n\n",
        "    print(f'  {cls}: {n} images')\n",
        "print(f'  Total: {total} images')\n",
        "assert total > 0, 'Organized folder is empty!'\n",
        "print('\\nDataset ready for training.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Cell 6 — Training"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "from torch.utils.data import DataLoader, random_split, Dataset\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "CLASSES     = ['minor', 'moderate', 'severe']\n",
        "CLASS_TO_IDX = {c: i for i, c in enumerate(CLASSES)}\n",
        "\n",
        "TRAIN_TRANSFORMS = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=20),\n",
        "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.3, hue=0.1),\n",
        "    transforms.RandomGrayscale(p=0.05),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "VAL_TRANSFORMS = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "class CarDamageDataset(Dataset):\n",
        "    def __init__(self, image_dir, transform=None):\n",
        "        self.samples   = []\n",
        "        self.transform = transform\n",
        "        for cls in CLASSES:\n",
        "            cls_dir = os.path.join(image_dir, cls)\n",
        "            if not os.path.exists(cls_dir):\n",
        "                print(f'WARNING: {cls_dir} not found, skipping.')\n",
        "                continue\n",
        "            found = 0\n",
        "            for fname in os.listdir(cls_dir):\n",
        "                if fname.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    self.samples.append(\n",
        "                        (os.path.join(cls_dir, fname), CLASS_TO_IDX[cls])\n",
        "                    )\n",
        "                    found += 1\n",
        "            print(f'  {cls}: {found} images')\n",
        "        print(f'  Total samples loaded: {len(self.samples)}')\n",
        "\n",
        "    def __len__(self): return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, label = self.samples[idx]\n",
        "        try:\n",
        "            img = Image.open(path).convert('RGB')\n",
        "        except Exception:\n",
        "            img = Image.new('RGB', (224, 224), (128, 128, 128))\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "# Wrapper to apply val transforms correctly without mutating train dataset\n",
        "class ValDataset(Dataset):\n",
        "    def __init__(self, subset, transform):\n",
        "        self.subset    = subset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self): return len(self.subset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, label = self.subset.dataset.samples[self.subset.indices[idx]]\n",
        "        try:\n",
        "            img = Image.open(path).convert('RGB')\n",
        "        except Exception:\n",
        "            img = Image.new('RGB', (224, 224), (128, 128, 128))\n",
        "        return self.transform(img), label\n",
        "\n",
        "class DamageClassifier(nn.Module):\n",
        "    def __init__(self, num_classes=3, pretrained=True):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(\n",
        "            'efficientnet_b0', pretrained=pretrained, num_classes=num_classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x): return self.backbone(x)\n",
        "\n",
        "    def save(self, path): torch.save(self.state_dict(), path)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, path, num_classes=3):\n",
        "        m = cls(num_classes=num_classes, pretrained=False)\n",
        "        m.load_state_dict(torch.load(path, map_location='cpu'))\n",
        "        m.eval()\n",
        "        return m\n",
        "\n",
        "# ── Config ───────────────────────────────────────────────────────\n",
        "DEVICE    = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "DATA_DIR  = '/content/data/organized'\n",
        "SAVE_PATH = '/content/best_model.pt'\n",
        "EPOCHS    = 20\n",
        "BATCH     = 16\n",
        "LR        = 3e-4\n",
        "PATIENCE  = 7\n",
        "\n",
        "print(f'Device: {DEVICE}')\n",
        "\n",
        "# ── Dataset ──────────────────────────────────────────────────────\n",
        "full_ds = CarDamageDataset(DATA_DIR, transform=TRAIN_TRANSFORMS)\n",
        "assert len(full_ds) > 0, 'Dataset empty — did Cell 5 complete successfully?'\n",
        "\n",
        "n_val   = max(1, int(len(full_ds) * 0.2))\n",
        "n_train = len(full_ds) - n_val\n",
        "train_ds, val_ds = random_split(full_ds, [n_train, n_val],\n",
        "                                generator=torch.Generator().manual_seed(42))\n",
        "val_ds = ValDataset(val_ds, VAL_TRANSFORMS)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True,\n",
        "                          num_workers=2, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH, shuffle=False,\n",
        "                          num_workers=2, pin_memory=True)\n",
        "\n",
        "print(f'Train: {n_train} | Val: {n_val}')\n",
        "\n",
        "# ── Model ────────────────────────────────────────────────────────\n",
        "model = DamageClassifier(num_classes=3).to(DEVICE)\n",
        "\n",
        "# Freeze entire backbone first, only train the classifier head\n",
        "for p in model.backbone.parameters():\n",
        "    p.requires_grad = False\n",
        "for p in model.backbone.classifier.parameters():\n",
        "    p.requires_grad = True\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "optimizer = AdamW(\n",
        "    filter(lambda p: p.requires_grad, model.parameters()),\n",
        "    lr=LR, weight_decay=0.01\n",
        ")\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
        "\n",
        "best_val_acc    = 0.0\n",
        "patience_counter = 0\n",
        "unfrozen        = False\n",
        "\n",
        "# ── Training loop ────────────────────────────────────────────────\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    # After 2 warmup epochs, unfreeze last 3 blocks for fine-tuning\n",
        "    if epoch == 2 and not unfrozen:\n",
        "        for p in model.backbone.blocks[-3:].parameters():\n",
        "            p.requires_grad = True\n",
        "        optimizer = AdamW(\n",
        "            filter(lambda p: p.requires_grad, model.parameters()),\n",
        "            lr=LR / 5, weight_decay=0.01\n",
        "        )\n",
        "        scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS - 2)\n",
        "        unfrozen  = True\n",
        "        print('  [Epoch 3] Unfroze last 3 blocks for fine-tuning.')\n",
        "\n",
        "    # Train\n",
        "    model.train()\n",
        "    correct, total = 0, 0\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        out  = model(imgs)\n",
        "        loss = criterion(out, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        correct += (out.detach().argmax(1) == labels).sum().item()\n",
        "        total   += labels.size(0)\n",
        "\n",
        "    # Validate\n",
        "    model.eval()\n",
        "    val_correct, val_total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in val_loader:\n",
        "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
        "            val_correct += (model(imgs).argmax(1) == labels).sum().item()\n",
        "            val_total   += labels.size(0)\n",
        "\n",
        "    train_acc = correct / total\n",
        "    val_acc   = val_correct / val_total\n",
        "    scheduler.step()\n",
        "    print(f'Epoch {epoch+1:02d}/{EPOCHS} | '\n",
        "          f'Train: {train_acc:.3f} | Val: {val_acc:.3f}')\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc     = val_acc\n",
        "        patience_counter = 0\n",
        "        model.save(SAVE_PATH)\n",
        "        print(f'  Saved best model (val_acc={val_acc:.3f})')\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= PATIENCE:\n",
        "            print('Early stopping triggered.')\n",
        "            break\n",
        "\n",
        "print(f'\\nTraining complete. Best val_acc: {best_val_acc:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Cell 7 — Save best_model.pt to Google Drive"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "assert os.path.exists('/content/best_model.pt'), \\\n",
        "    'best_model.pt not found — did training complete without errors?'\n",
        "\n",
        "!mkdir -p '/content/drive/MyDrive/claimlens'\n",
        "!cp /content/best_model.pt '/content/drive/MyDrive/claimlens/best_model.pt'\n",
        "\n",
        "size_mb = os.path.getsize('/content/best_model.pt') / 1024 / 1024\n",
        "print(f'Saved to Google Drive.')\n",
        "print(f'Size: {size_mb:.1f} MB')\n",
        "print(f'Path: /content/drive/MyDrive/claimlens/best_model.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Cell 8 — Final confirmation"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('=' * 50)\n",
        "print('PHASE 2 TRAINING COMPLETE')\n",
        "print('=' * 50)\n",
        "print(f'Best validation accuracy: {best_val_acc:.3f}')\n",
        "print()\n",
        "print('Next steps:')\n",
        "print('1. Open Google Drive -> claimlens -> download best_model.pt')\n",
        "print('2. Place it at: models/damage_classifier/best_model.pt')\n",
        "print('3. Tell your coding agent: best_model.pt is placed, run Phase 2 verification')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
